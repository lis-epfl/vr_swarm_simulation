{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f84582e",
   "metadata": {},
   "source": [
    "# OpenCV Drone Image Analysis Exploration\n",
    "\n",
    "This notebook is for exploring OpenCV functions with drone images captured from your VR swarm simulation.\n",
    "\n",
    "**Target Image:** `drone_0_20251009_164732.png`\n",
    "\n",
    "**Goals:**\n",
    "- Understand different OpenCV processing techniques\n",
    "- Experiment with various computer vision algorithms\n",
    "- Visualize results for different approaches\n",
    "- Test what works best for drone image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7be002",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure matplotlib for better image display\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224ad61",
   "metadata": {},
   "source": [
    "## 2. Load and Display the Drone Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad25e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your drone image\n",
    "# Adjust this path if your image is in a different location\n",
    "image_path = \"../../DroneImages/drone_0_20251009_164732.png\"\n",
    "\n",
    "# Alternative paths to try if the above doesn't work\n",
    "alternative_paths = [\n",
    "    \"../../../DroneImages/drone_0_20251009_164732.png\",\n",
    "    \"../../../../DroneImages/drone_0_20251009_164732.png\",\n",
    "    \"./drone_0_20251009_164732.png\",  # If you copy the image to this folder\n",
    "]\n",
    "\n",
    "# Try to load the image\n",
    "image = None\n",
    "actual_path = None\n",
    "\n",
    "for path in [image_path] + alternative_paths:\n",
    "    if os.path.exists(path):\n",
    "        image = cv2.imread(path)\n",
    "        actual_path = path\n",
    "        print(f\"‚úÖ Image loaded successfully from: {path}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"‚ùå Image not found at: {path}\")\n",
    "\n",
    "if image is None:\n",
    "    print(\"\\nüö® Could not find the image file!\")\n",
    "    print(\"Please:\")\n",
    "    print(\"1. Check if the image exists in the DroneImages folder\")\n",
    "    print(\"2. Update the image_path variable above with the correct path\")\n",
    "    print(\"3. Or copy the image to this notebook's folder\")\n",
    "else:\n",
    "    # Convert BGR to RGB for matplotlib display\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display basic image info\n",
    "    height, width, channels = image.shape\n",
    "    print(f\"\\nüì∏ Image Information:\")\n",
    "    print(f\"   Size: {width} x {height} pixels\")\n",
    "    print(f\"   Channels: {channels}\")\n",
    "    print(f\"   Data type: {image.dtype}\")\n",
    "    print(f\"   File size: {os.path.getsize(actual_path) / 1024:.1f} KB\")\n",
    "    \n",
    "    # Display the original image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Original Drone Image\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d01da",
   "metadata": {},
   "source": [
    "## 3. Basic Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73804c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Convert to different color spaces\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Create a subplot to show different color spaces\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Original\n",
    "    axes[0, 0].imshow(image_rgb)\n",
    "    axes[0, 0].set_title('Original (RGB)')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Grayscale\n",
    "    axes[0, 1].imshow(gray, cmap='gray')\n",
    "    axes[0, 1].set_title('Grayscale')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # HSV (showing Hue channel)\n",
    "    axes[1, 0].imshow(hsv[:,:,0], cmap='hsv')\n",
    "    axes[1, 0].set_title('HSV - Hue Channel')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # LAB (showing L channel)\n",
    "    axes[1, 1].imshow(lab[:,:,0], cmap='gray')\n",
    "    axes[1, 1].set_title('LAB - Lightness Channel')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Image statistics\n",
    "    print(f\"\\nüìä Image Statistics:\")\n",
    "    print(f\"   Mean intensity: {np.mean(gray):.2f}\")\n",
    "    print(f\"   Standard deviation: {np.std(gray):.2f}\")\n",
    "    print(f\"   Min intensity: {np.min(gray)}\")\n",
    "    print(f\"   Max intensity: {np.max(gray)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce5c67",
   "metadata": {},
   "source": [
    "## 4. Edge Detection Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9523422",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Different edge detection methods\n",
    "    \n",
    "    # Canny edge detection with different parameters\n",
    "    canny1 = cv2.Canny(gray, 50, 150)    # Low threshold\n",
    "    canny2 = cv2.Canny(gray, 100, 200)   # Medium threshold  \n",
    "    canny3 = cv2.Canny(gray, 150, 250)   # High threshold\n",
    "    \n",
    "    # Sobel edge detection\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Laplacian edge detection\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(canny1, cmap='gray')\n",
    "    axes[0, 0].set_title('Canny (50, 150) - Sensitive')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(canny2, cmap='gray')\n",
    "    axes[0, 1].set_title('Canny (100, 200) - Balanced')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(canny3, cmap='gray')\n",
    "    axes[0, 2].set_title('Canny (150, 250) - Conservative')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(sobel_combined, cmap='gray')\n",
    "    axes[1, 0].set_title('Sobel Combined')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(np.abs(laplacian), cmap='gray')\n",
    "    axes[1, 1].set_title('Laplacian')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    axes[1, 2].imshow(gray, cmap='gray')\n",
    "    axes[1, 2].set_title('Original Grayscale')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Count edge pixels for each method\n",
    "    print(f\"\\nüîç Edge Detection Analysis:\")\n",
    "    print(f\"   Canny (50,150): {np.sum(canny1 > 0)} edge pixels\")\n",
    "    print(f\"   Canny (100,200): {np.sum(canny2 > 0)} edge pixels\")\n",
    "    print(f\"   Canny (150,250): {np.sum(canny3 > 0)} edge pixels\")\n",
    "    print(f\"   Sobel: {np.sum(sobel_combined > 50)} edge pixels (threshold 50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98956242",
   "metadata": {},
   "source": [
    "## 5. Object Detection with Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Use the best Canny result for contour detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours by area\n",
    "    min_area = 100\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "    \n",
    "    print(f\"\\nüéØ Contour Analysis:\")\n",
    "    print(f\"   Total contours found: {len(contours)}\")\n",
    "    print(f\"   Large contours (area > {min_area}): {len(large_contours)}\")\n",
    "    \n",
    "    # Create images with contours drawn\n",
    "    contour_image1 = image_rgb.copy()\n",
    "    contour_image2 = image_rgb.copy()\n",
    "    \n",
    "    # Draw all contours\n",
    "    for i, cnt in enumerate(contours):\n",
    "        color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        cv2.drawContours(contour_image1, [cnt], -1, color, 2)\n",
    "    \n",
    "    # Draw only large contours with bounding boxes\n",
    "    for i, cnt in enumerate(large_contours):\n",
    "        # Draw contour\n",
    "        cv2.drawContours(contour_image2, [cnt], -1, (0, 255, 0), 3)\n",
    "        \n",
    "        # Draw bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(contour_image2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Add area text\n",
    "        area = cv2.contourArea(cnt)\n",
    "        cv2.putText(contour_image2, f'Area: {int(area)}', (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(edges, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Edge Detection (Canny)')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(contour_image1)\n",
    "    axes[0, 1].set_title(f'All Contours ({len(contours)} found)')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(contour_image2)\n",
    "    axes[1, 0].set_title(f'Large Objects ({len(large_contours)} found)')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(image_rgb)\n",
    "    axes[1, 1].set_title('Original Image')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze the largest objects\n",
    "    if large_contours:\n",
    "        print(f\"\\nüìã Top 5 Largest Objects:\")\n",
    "        sorted_contours = sorted(large_contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "        for i, cnt in enumerate(sorted_contours):\n",
    "            area = cv2.contourArea(cnt)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = w / h if h != 0 else 0\n",
    "            print(f\"   {i+1}. Area: {int(area)}, Size: {w}x{h}, Aspect Ratio: {aspect_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b0f39",
   "metadata": {},
   "source": [
    "## 6. Feature Detection (Keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe92a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Initialize feature detectors\n",
    "    orb = cv2.ORB_create(nfeatures=500)\n",
    "    \n",
    "    # Try SIFT if available (might not be in all OpenCV versions)\n",
    "    try:\n",
    "        sift = cv2.SIFT_create(nfeatures=500)\n",
    "        sift_available = True\n",
    "    except:\n",
    "        print(\"SIFT not available in this OpenCV version\")\n",
    "        sift_available = False\n",
    "    \n",
    "    # Detect ORB keypoints\n",
    "    orb_keypoints, orb_descriptors = orb.detectAndCompute(gray, None)\n",
    "    orb_image = cv2.drawKeypoints(image_rgb.copy(), orb_keypoints, None, \n",
    "                                  color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    print(f\"\\nüîë Feature Detection Results:\")\n",
    "    print(f\"   ORB keypoints found: {len(orb_keypoints)}\")\n",
    "    \n",
    "    if sift_available:\n",
    "        # Detect SIFT keypoints\n",
    "        sift_keypoints, sift_descriptors = sift.detectAndCompute(gray, None)\n",
    "        sift_image = cv2.drawKeypoints(image_rgb.copy(), sift_keypoints, None, \n",
    "                                      color=(255, 0, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        print(f\"   SIFT keypoints found: {len(sift_keypoints)}\")\n",
    "        \n",
    "        # Display both\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        axes[0].imshow(image_rgb)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(orb_image)\n",
    "        axes[1].set_title(f'ORB Features ({len(orb_keypoints)} points)')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(sift_image)\n",
    "        axes[2].set_title(f'SIFT Features ({len(sift_keypoints)} points)')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "    else:\n",
    "        # Display only ORB\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        axes[0].imshow(image_rgb)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(orb_image)\n",
    "        axes[1].set_title(f'ORB Features ({len(orb_keypoints)} points)')\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze keypoint distribution\n",
    "    if orb_keypoints:\n",
    "        keypoint_coords = np.array([kp.pt for kp in orb_keypoints])\n",
    "        print(f\"\\nüìç Keypoint Distribution:\")\n",
    "        print(f\"   X range: {keypoint_coords[:, 0].min():.1f} - {keypoint_coords[:, 0].max():.1f}\")\n",
    "        print(f\"   Y range: {keypoint_coords[:, 1].min():.1f} - {keypoint_coords[:, 1].max():.1f}\")\n",
    "        print(f\"   Average response: {np.mean([kp.response for kp in orb_keypoints]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ce1c4",
   "metadata": {},
   "source": [
    "## 7. Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ad666",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Color histogram analysis\n",
    "    colors = ('b', 'g', 'r')\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # RGB Histograms\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, color in enumerate(colors):\n",
    "        hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "        plt.plot(hist, color=color, alpha=0.7)\n",
    "    plt.title('RGB Color Histograms')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(['Blue', 'Green', 'Red'])\n",
    "    \n",
    "    # Grayscale histogram\n",
    "    plt.subplot(1, 3, 2)\n",
    "    hist_gray = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    plt.plot(hist_gray, color='black')\n",
    "    plt.title('Grayscale Histogram')\n",
    "    plt.xlabel('Pixel Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    # HSV Hue histogram\n",
    "    plt.subplot(1, 3, 3)\n",
    "    hist_hue = cv2.calcHist([hsv], [0], None, [180], [0, 180])\n",
    "    plt.plot(hist_hue, color='purple')\n",
    "    plt.title('Hue Histogram')\n",
    "    plt.xlabel('Hue Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Dominant colors using K-means\n",
    "    def find_dominant_colors(image, k=5):\n",
    "        data = image.reshape((-1, 3))\n",
    "        data = np.float32(data)\n",
    "        \n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "        _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "        \n",
    "        centers = np.uint8(centers)\n",
    "        return centers, labels\n",
    "    \n",
    "    # Find dominant colors\n",
    "    dominant_colors, color_labels = find_dominant_colors(image_rgb, k=5)\n",
    "    \n",
    "    # Create color palette\n",
    "    def create_color_palette(colors):\n",
    "        palette = np.zeros((100, len(colors) * 100, 3), dtype=np.uint8)\n",
    "        for i, color in enumerate(colors):\n",
    "            palette[:, i*100:(i+1)*100] = color\n",
    "        return palette\n",
    "    \n",
    "    palette = create_color_palette(dominant_colors)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.imshow(palette)\n",
    "    plt.title('Top 5 Dominant Colors')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add color values as text\n",
    "    for i, color in enumerate(dominant_colors):\n",
    "        plt.text(i*100 + 50, 50, f'RGB\\n{color[0], color[1], color[2]}', \n",
    "                ha='center', va='center', fontsize=10, \n",
    "                color='white' if np.mean(color) < 128 else 'black')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüé® Color Analysis:\")\n",
    "    print(f\"   Dominant colors (RGB):\")\n",
    "    for i, color in enumerate(dominant_colors):\n",
    "        print(f\"     {i+1}. RGB({color[0]}, {color[1]}, {color[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d95123",
   "metadata": {},
   "source": [
    "## 8. Advanced Processing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25042af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if image is not None:\n",
    "    # Morphological operations\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    \n",
    "    # Start with a binary image (thresholded)\n",
    "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Morphological operations\n",
    "    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    gradient = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # Noise reduction filters\n",
    "    gaussian_blur = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    median_blur = cv2.medianBlur(gray, 15)\n",
    "    bilateral_filter = cv2.bilateralFilter(gray, 15, 80, 80)\n",
    "    \n",
    "    # Display morphological results\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(binary, cmap='gray')\n",
    "    axes[0, 0].set_title('Binary Threshold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(opening, cmap='gray')\n",
    "    axes[0, 1].set_title('Morphological Opening')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(closing, cmap='gray')\n",
    "    axes[0, 2].set_title('Morphological Closing')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(gradient, cmap='gray')\n",
    "    axes[1, 0].set_title('Morphological Gradient')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(gaussian_blur, cmap='gray')\n",
    "    axes[1, 1].set_title('Gaussian Blur')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    axes[1, 2].imshow(bilateral_filter, cmap='gray')\n",
    "    axes[1, 2].set_title('Bilateral Filter')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüîß Advanced Processing Applied:\")\n",
    "    print(f\"   - Binary thresholding\")\n",
    "    print(f\"   - Morphological operations (opening, closing, gradient)\")\n",
    "    print(f\"   - Noise reduction filters (Gaussian, median, bilateral)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9108f",
   "metadata": {},
   "source": [
    "## 9. Custom Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2653725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_drone_image(image_path):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis function for drone images.\n",
    "    This is a template you can customize based on your findings above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to RGB and grayscale\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Analysis results dictionary\n",
    "    results = {\n",
    "        'image_info': {\n",
    "            'width': image.shape[1],\n",
    "            'height': image.shape[0],\n",
    "            'channels': image.shape[2]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 1. Edge detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    results['edges'] = {\n",
    "        'edge_pixels': int(np.sum(edges > 0)),\n",
    "        'edge_density': float(np.sum(edges > 0) / (edges.shape[0] * edges.shape[1]))\n",
    "    }\n",
    "    \n",
    "    # 2. Object detection via contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100]\n",
    "    \n",
    "    objects = []\n",
    "    for cnt in large_contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        objects.append({\n",
    "            'area': float(area),\n",
    "            'bounding_box': [int(x), int(y), int(w), int(h)],\n",
    "            'aspect_ratio': float(w/h) if h > 0 else 0,\n",
    "            'center': [float(x + w/2), float(y + h/2)]\n",
    "        })\n",
    "    \n",
    "    results['objects'] = {\n",
    "        'count': len(objects),\n",
    "        'details': objects\n",
    "    }\n",
    "    \n",
    "    # 3. Feature detection\n",
    "    orb = cv2.ORB_create(nfeatures=500)\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    \n",
    "    results['features'] = {\n",
    "        'keypoint_count': len(keypoints),\n",
    "        'feature_density': float(len(keypoints) / (gray.shape[0] * gray.shape[1]))\n",
    "    }\n",
    "    \n",
    "    # 4. Image statistics\n",
    "    results['statistics'] = {\n",
    "        'mean_intensity': float(np.mean(gray)),\n",
    "        'std_intensity': float(np.std(gray)),\n",
    "        'contrast': float(np.std(gray) / np.mean(gray)) if np.mean(gray) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # 5. Create visualization\n",
    "    vis_image = image_rgb.copy()\n",
    "    \n",
    "    # Draw objects\n",
    "    for obj in objects:\n",
    "        x, y, w, h = obj['bounding_box']\n",
    "        cv2.rectangle(vis_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv2.putText(vis_image, f\"A:{int(obj['area'])}\", (x, y-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    for kp in keypoints[:50]:  # Limit to first 50 for visibility\n",
    "        x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "        cv2.circle(vis_image, (x, y), 3, (0, 255, 0), 1)\n",
    "    \n",
    "    return results, vis_image\n",
    "\n",
    "# Test the analysis function\n",
    "if image is not None:\n",
    "    print(\"\\nüß™ Testing Custom Analysis Function...\")\n",
    "    analysis_results, visualization = analyze_drone_image(actual_path)\n",
    "    \n",
    "    if analysis_results:\n",
    "        print(f\"\\nüìä Analysis Results:\")\n",
    "        print(f\"   Image size: {analysis_results['image_info']['width']}x{analysis_results['image_info']['height']}\")\n",
    "        print(f\"   Edge density: {analysis_results['edges']['edge_density']:.4f}\")\n",
    "        print(f\"   Objects found: {analysis_results['objects']['count']}\")\n",
    "        print(f\"   Keypoints: {analysis_results['features']['keypoint_count']}\")\n",
    "        print(f\"   Mean intensity: {analysis_results['statistics']['mean_intensity']:.2f}\")\n",
    "        print(f\"   Contrast ratio: {analysis_results['statistics']['contrast']:.3f}\")\n",
    "        \n",
    "        # Display visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(visualization)\n",
    "        plt.title('Custom Analysis: Objects (Red Boxes) + Keypoints (Green Circles)')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Show largest objects\n",
    "        if analysis_results['objects']['details']:\n",
    "            largest_objects = sorted(analysis_results['objects']['details'], \n",
    "                                   key=lambda x: x['area'], reverse=True)[:3]\n",
    "            print(f\"\\nüèÜ Top 3 Largest Objects:\")\n",
    "            for i, obj in enumerate(largest_objects):\n",
    "                print(f\"   {i+1}. Area: {obj['area']:.0f}, Center: ({obj['center'][0]:.0f}, {obj['center'][1]:.0f})\")\n",
    "    else:\n",
    "        print(\"‚ùå Analysis failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d09ed",
   "metadata": {},
   "source": [
    "## 10. Experiment Zone - Try Your Own Ideas!\n",
    "\n",
    "Use this cell to experiment with different OpenCV functions and parameters. Here are some ideas to try:\n",
    "\n",
    "1. **Different edge detection parameters**\n",
    "2. **Color segmentation** (isolating specific colors)\n",
    "3. **Template matching** (finding specific patterns)\n",
    "4. **Blob detection**\n",
    "5. **Line detection** (Hough transform)\n",
    "6. **Corner detection** (Harris corners)\n",
    "\n",
    "Copy and modify code from the cells above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments go here!\n",
    "# Copy code from above cells and modify it\n",
    "\n",
    "if image is not None:\n",
    "    print(\"üöÄ Ready for your experiments!\")\n",
    "    print(\"Available variables:\")\n",
    "    print(\"   - image: Original BGR image\")\n",
    "    print(\"   - image_rgb: RGB version for display\")\n",
    "    print(\"   - gray: Grayscale version\")\n",
    "    print(\"   - hsv: HSV color space\")\n",
    "    print(\"\\nTry different OpenCV functions and see what works best for your drone images!\")\n",
    "    \n",
    "    # Example experiment: Try different threshold values\n",
    "    # Uncomment and modify:\n",
    "    \n",
    "    # for threshold in [50, 100, 150, 200]:\n",
    "    #     edges = cv2.Canny(gray, threshold, threshold*2)\n",
    "    #     edge_count = np.sum(edges > 0)\n",
    "    #     print(f\"Threshold {threshold}: {edge_count} edge pixels\")\n",
    "else:\n",
    "    print(\"Please load an image first by running the cells above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce125e",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook explored various OpenCV techniques for drone image analysis:\n",
    "\n",
    "**‚úÖ What we covered:**\n",
    "- Basic image processing and color spaces\n",
    "- Edge detection with different algorithms\n",
    "- Object detection using contours\n",
    "- Feature detection with ORB/SIFT\n",
    "- Color analysis and dominant colors\n",
    "- Advanced morphological operations\n",
    "- Custom analysis function template\n",
    "\n",
    "**üéØ Next steps:**\n",
    "1. **Identify which techniques work best** for your specific drone images\n",
    "2. **Optimize parameters** for your use case (edge thresholds, contour areas, etc.)\n",
    "3. **Integrate the best methods** into your Unity-Python pipeline\n",
    "4. **Add specific detection logic** for objects you care about (buildings, vehicles, etc.)\n",
    "\n",
    "**üîß Integration tips:**\n",
    "- Use the `analyze_drone_image()` function as a starting point\n",
    "- Focus on the most useful metrics for your application\n",
    "- Consider real-time performance when choosing algorithms\n",
    "- Test with multiple drone images to ensure robustness\n",
    "\n",
    "Feel free to experiment more and find what works best for your specific needs!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
